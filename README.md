# Pipeline de DonnÃ©es Notion â†’ SQLite â†’ Metabase

Pipeline ETL complÃ¨te pour extraire des donnÃ©es depuis Notion, les stocker dans SQLite et les visualiser avec Metabase. 100% gratuit et local.

**ğŸ“º [Voir le tutoriel YouTube](LIEN_YOUTUBE)**
**ğŸ“‹ [Template Notion Ã  dupliquer](LIEN_NOTION_TEMPLATE)**
**ğŸ“– [Documentation API Notion](https://developers.notion.com/)**

---

## ğŸ¯ Ce que tu vas construire

- **SystÃ¨me d'ingestion** : Extraction de donnÃ©es via l'API Notion avec Python
- **SystÃ¨me de stockage** : Base de donnÃ©es SQLite locale
- **Dashboard Metabase** : Visualisation dans un container Docker
- **Automatisation** : RafraÃ®chissement automatique avec cron jobs

---

## âš™ï¸ PrÃ©requis

- Python 3.8+
- Docker
- Compte Notion avec accÃ¨s API
- Git

---

## ğŸš€ Installation

### 1. Cloner le projet
```bash
git clone https://github.com/TON_USERNAME/notionLearnings.git
cd notionLearnings
```

### 2. CrÃ©er l'environnement virtuel
```bash
python3 -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configurer les variables d'environnement
```bash
cp .env.example .env
```

Ã‰dite `.env` avec tes identifiants :
- **NOTION_TOKEN** : CrÃ©e une intÃ©gration sur [Notion Developers](https://www.notion.so/my-integrations)
- **DATA_SOURCE_ID** : ID de ta base de donnÃ©es Notion (voir vidÃ©o YouTube)

---

## ğŸ“Š Utilisation

### Extraction manuelle
```bash
python extraction.py
```

Les donnÃ©es sont sauvegardÃ©es dans `notion.db`.

### Lancer Metabase avec Docker
```bash
docker run -d -p 3000:3000 \
  -v $(pwd)/notion.db:/metabase-data/notion.db \
  --name metabase \
  metabase/metabase
```

AccÃ¨de Ã  Metabase : [http://localhost:3000](http://localhost:3000)

**Configuration Metabase :**
1. CrÃ©er un compte admin
2. Ajouter une base de donnÃ©es SQLite
3. Chemin : `/metabase-data/notion.db`
4. CrÃ©er ton dashboard

---

## ğŸ”„ Automatisation (Cron)

Pour rafraÃ®chir les donnÃ©es automatiquement :

```bash
crontab -e
```

Ajoute cette ligne (exÃ©cution toutes les heures) :
```bash
0 * * * * /chemin/vers/notionLearnings/run_extraction.sh
```

Les logs sont dans `cron.log`.

---

## ğŸ“ Structure du projet

```
notionLearnings/
â”œâ”€â”€ extraction.py              # Script ETL principal
â”œâ”€â”€ run_extraction.sh          # Wrapper pour cron
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ .env.example              # Template configuration
â”œâ”€â”€ notion.db                 # Base de donnÃ©es (gÃ©nÃ©rÃ©)
â”œâ”€â”€ cron.log                  # Logs d'exÃ©cution
â””â”€â”€ Notebooks/
    â”œâ”€â”€ Exploration.ipynb              # Exploration des donnÃ©es
    â””â”€â”€ datasourceExploration.ipynb    # DÃ©couverte API
```

---

## ğŸ› ï¸ SchÃ©ma des donnÃ©es

La table `learnings` contient :
- `date_started` : Date de dÃ©but
- `subject` : Sujet (Business, Tech, Musique, etc.)
- `priority` : PrioritÃ© (High, Medium, Low)
- `source` : Source (Book, YouTube, Udemy)
- `scope` : Ampleur (Quick Win, Medium, Long, Epic)
- `status` : Statut (In Progress, Completed, Not Started)
- `url` : Lien vers la ressource
- `topic` : ThÃ¨me gÃ©nÃ©ral
- `title` : Nom de la ressource

---

## ğŸ“ Notes importantes

âš ï¸ **Windows/Linux** : Certaines commandes diffÃ¨rent. Utilise ChatGPT pour adapter les commandes terminal Ã  ton systÃ¨me.

ğŸ’¡ **Notebooks** : Les fichiers Jupyter dans `Notebooks/` montrent comment explorer l'API Notion et transformer les donnÃ©es.

---

## ğŸ”— Ressources

- [Documentation Notion API](https://developers.notion.com/)
- [Documentation Metabase](https://www.metabase.com/docs/)
- [Tutoriel vidÃ©o complet](LIEN_YOUTUBE)

---

## ğŸ“„ Licence

MIT - Utilise et modifie librement ce projet.
